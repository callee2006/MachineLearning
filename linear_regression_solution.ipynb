{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression_solution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/callee2006/MachineLearning/blob/master/linear_regression_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzHEwOGyzQQb",
        "colab_type": "text"
      },
      "source": [
        "This file contains practice examples of the following topics:\n",
        "\n",
        "* Linear Regression\t\n",
        "  - Linear regression\n",
        "  - Ridge ($L_2$ regularization)\n",
        "  - Lasso ($L_1$ regularization)\n",
        "  - ElasticNet ($L_1$ + $L_2$ regularization)\n",
        "\t\n",
        "* Linear Classification\t\n",
        "  -\tLogistic regression\n",
        "\n",
        "(Most of the contents and code are from \"Introduction to Machine Learning with Python\" by Andreas C. Müller & Sarah Guido)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTzTGF7wWVGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIn3aQngJ7q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install mglearn\n",
        "\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import mglearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b8Tof_xy9ryB"
      },
      "source": [
        "# Linear regression\n",
        "\n",
        ">$\\hat{y}=wx + b$\n",
        "\n",
        ">$\\hat{y}=w_1x_1+ w_2x_2+ ...+ b$\n",
        "\n",
        ">$Loss_{linear} = \\frac{1}{2N} \\sum_i{(\\hat{y}-y)^2}$\n",
        "(least square)\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va04ZHqD-yDw",
        "colab_type": "text"
      },
      "source": [
        "## Linear regression on wave dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-PFWfbD9u2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mglearn.plots.plot_linear_regression_wave()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65N_tdUc92Q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# creates wave data\n",
        "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
        "\n",
        "# split into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wumW0e_4-BVS",
        "colab_type": "code",
        "outputId": "144c5f04-aa1d-474a-9cc0-c704117b240e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# regression (parameter estimation)\n",
        "lr = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# check coeeficients and intercept\n",
        "print(\"lr.coef_: \", lr.coef_)             # W\n",
        "print(\"lr.intercept_:\", lr.intercept_)      # b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr.coef_:  [0.39390555]\n",
            "lr.intercept_: -0.031804343026759746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuMJWnPt4Kqd",
        "colab_type": "text"
      },
      "source": [
        "score() Returns the coefficient of determination $R^2$ of the prediction $(1-u/v)$\n",
        " \n",
        " $u=\\sum(\\hat{y}-y)^2$ and $v=\\sum(y-\\bar{y})$, where $\\bar{y}$ is the mean of $y$\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_iqvTiT-DHM",
        "colab_type": "code",
        "outputId": "9621c531-6b2f-45a6-cf1a-28f988e1430e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# evaluation\n",
        "print(\"Training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.67\n",
            "Test set score: 0.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBkVL2fH6IY8",
        "colab_type": "text"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66rq0_UN6JpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.arange(-10., 10., 0.1)               \n",
        "print(\"X = \", X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUhEYkTxAZ2P",
        "colab_type": "text"
      },
      "source": [
        "## Linear regression on Boston house price data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TPeDRtZ-phA",
        "colab_type": "code",
        "outputId": "fed25f48-3d04-44c8-d5de-1ac00335eccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# load boston data\n",
        "X, y = mglearn.datasets.load_extended_boston()\n",
        "\n",
        "# split into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "print(\"X_train.shape =\", X_train.shape)\n",
        "print(\"y_train.shape =\", y_train.shape)\n",
        "print(\"X_test.shape =\", X_test.shape)\n",
        "print(\"y_test.shape =\", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape = (379, 104)\n",
            "y_train.shape = (379,)\n",
            "X_test.shape = (127, 104)\n",
            "y_test.shape = (127,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-AAALUUA1mX",
        "colab_type": "code",
        "outputId": "86aea6ca-e360-4b81-c908-7f88650ac353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "# create object \n",
        "lr = LinearRegression()\n",
        "\n",
        "# train\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# the above two statements can be combined as the next line\n",
        "# lr = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# check coefficients and intercept\n",
        "print(\"lr.coef_:\", lr.coef_)             # w\n",
        "print(\"lr.intercept_:\", lr.intercept_)   # b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr.coef_: [-4.12710947e+02 -5.22432068e+01 -1.31898815e+02 -1.20041365e+01\n",
            " -1.55107129e+01  2.87163342e+01  5.47040992e+01 -4.95346659e+01\n",
            "  2.65823927e+01  3.70620316e+01 -1.18281674e+01 -1.80581965e+01\n",
            " -1.95246830e+01  1.22025403e+01  2.98078144e+03  1.50084257e+03\n",
            "  1.14187325e+02 -1.69700520e+01  4.09613691e+01 -2.42636646e+01\n",
            "  5.76157466e+01  1.27812142e+03 -2.23986944e+03  2.22825472e+02\n",
            " -2.18201083e+00  4.29960320e+01 -1.33981515e+01 -1.93893485e+01\n",
            " -2.57541277e+00 -8.10130128e+01  9.66019367e+00  4.91423718e+00\n",
            " -8.12114800e-01 -7.64694179e+00  3.37837099e+01 -1.14464390e+01\n",
            "  6.85083979e+01 -1.73753604e+01  4.28128204e+01  1.13988209e+00\n",
            " -7.72696840e-01  5.68255921e+01  1.42875996e+01  5.39551110e+01\n",
            " -3.21709644e+01  1.92709675e+01 -1.38852338e+01  6.06343266e+01\n",
            " -1.23153942e+01 -1.20041365e+01 -1.77243899e+01 -3.39868183e+01\n",
            "  7.08999816e+00 -9.22538241e+00  1.71980268e+01 -1.27718431e+01\n",
            " -1.19727581e+01  5.73871915e+01 -1.75331865e+01  4.10103194e+00\n",
            "  2.93666477e+01 -1.76611772e+01  7.84049424e+01 -3.19098015e+01\n",
            "  4.81752461e+01 -3.95344813e+01  5.22959055e+00  2.19982410e+01\n",
            "  2.56483934e+01 -4.99982035e+01  2.91457545e+01  8.94267456e+00\n",
            " -7.16599297e+01 -2.28147862e+01  8.40660981e+00 -5.37905422e+00\n",
            "  1.20137322e+00 -5.20877186e+00  4.11452351e+01 -3.78250760e+01\n",
            " -2.67163851e+00 -2.55217108e+01 -3.33982030e+01  4.62272693e+01\n",
            " -2.41509169e+01 -1.77532970e+01 -1.39723701e+01 -2.35522208e+01\n",
            "  3.68353800e+01 -9.46890859e+01  1.44302810e+02 -1.51158659e+01\n",
            " -1.49513436e+01 -2.87729579e+01 -3.17673192e+01  2.49551594e+01\n",
            " -1.84384534e+01  3.65073948e+00  1.73101122e+00  3.53617137e+01\n",
            "  1.19553429e+01  6.77025947e-01  2.73452009e+00  3.03720012e+01]\n",
            "lr.intercept_: 30.934563673645666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWUp8R6EA5mV",
        "colab_type": "code",
        "outputId": "739a24e7-585a-4c8e-af92-5749f6f878ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Performance evaluation\n",
        "print(\"Training score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(lr.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training score: 0.95\n",
            "Test score: 0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku3oWdAPPKpA",
        "colab_type": "code",
        "outputId": "79110a19-1d47-4bed-d262-5715f7b9d19a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# save and load model\n",
        "\n",
        "import pickle\n",
        "\n",
        "filename = 'linear'\n",
        "\n",
        "pickle.dump(lr, open(filename, 'wb'))\n",
        "lr2 = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "print(\"Training score: {:.2f}\".format(lr2.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(lr2.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training score: 0.95\n",
            "Test score: 0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6incDSiEOCG",
        "colab_type": "text"
      },
      "source": [
        "==> Big difference between training accuracy and test accuracy: overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3g4o-q8CTQ6",
        "colab_type": "text"
      },
      "source": [
        "## Ridge regression\n",
        "\n",
        "> linear regression + L2 regularization\n",
        "\n",
        "> $Loss_{ridge} = \\frac{1}{2N} \\sum_i{(\\hat{y}-y)^2}+\\alpha |W|^2$\n",
        "\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2dbfVjeBF0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Ridge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5bqcf-pD6_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ridge = Ridge().fit(X_train, y_train)           # by default, alpha = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XF6Eo_8D_CL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(\"ridge.coef_: {}\".format(ridge.coef_))             # w\n",
        "#print(\"ridge.intercept_: {}\".format(ridge.intercept_))   # b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seWbwxq2D8M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Training score: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(ridge.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koGC9RCVEYn2",
        "colab_type": "text"
      },
      "source": [
        "Lower training accuracy, but higher test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5w4Bo1rEYKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying higher alpha  --> too strong constraint\n",
        "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
        "\n",
        "print(\"Training score: {:.2f}\".format(ridge10.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(ridge10.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f7d0UwQFDHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying low alpha    --> appropriate constraint\n",
        "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
        "\n",
        "print(\"Training score: {:.2f}\".format(ridge01.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(ridge01.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_D4vLvUFMAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# coefficient magnitude\n",
        "plt.plot(ridge01.coef_, 'v', label=\"Ridge alpha=0.1\")\n",
        "plt.plot(ridge.coef_, 's', label=\"Ridge alpha=1\")\n",
        "plt.plot(ridge10.coef_, '^', label=\"Ridge alpha=10\")\n",
        "plt.plot(lr.coef_, 'o', label=\"LinearRegression\")\n",
        "plt.xlabel(\"Coefficient index\")\n",
        "plt.ylabel(\"Coefficient magnitude\")\n",
        "plt.hlines(0, 0, len(lr.coef_))\n",
        "plt.ylim(-25, 25)\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "377I-CihF3iS",
        "colab_type": "text"
      },
      "source": [
        "## Lasso regression\n",
        "\n",
        "> linear regression + L1 regularization\n",
        "\n",
        "> $Loss_{lasso}=\\frac{1}{2N} \\sum_i{(\\hat{y}-y)^2} +\\alpha |W|$\n",
        "\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3BsBAe8SJHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Lasso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D87pcTGxFiKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# by default, alpha = 1\n",
        "lasso = Lasso().fit(X_train, y_train)         # default alpha = 1, severe underfitting\n",
        "print(\"Training score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
        "print(\"Number of features used:\", np.sum(lasso.coef_ != 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWSRtuO1GHP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lasso with alpha = 0.01\n",
        "lasso001 = Lasso(0.01, max_iter=100000).fit(X_train, y_train)\n",
        "print(\"Training score: {:.2f}\".format(lasso001.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(lasso001.score(X_test, y_test)))\n",
        "print(\"Number of features used:\", np.sum(lasso001.coef_ != 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUi3xMVgGVUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lasso with alpha = 0.0001\n",
        "lasso0001 = Lasso(0.0001, max_iter=100000).fit(X_train, y_train)\n",
        "print(\"Training score: {:.2f}\".format(lasso0001.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(lasso0001.score(X_test, y_test)))\n",
        "print(\"Number of features used:\", np.sum(lasso0001.coef_ != 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSL1a8aDGqg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(lasso0001.coef_, 'v', label=\"Lasso alpha=0.0001\")\n",
        "plt.plot(lasso001.coef_, '^', label=\"Lasso alpha=0.01\")\n",
        "plt.plot(lasso.coef_, 's', label=\"Lasso alpha=1\")\n",
        "\n",
        "#plt.plot(ridge01.coef_, 'o', label=\"Ridge alpha=0.1\")\n",
        "plt.legend(ncol=2, loc=(0, 1.05))\n",
        "plt.ylim(-25, 25)\n",
        "plt.xlabel(\"Coefficient index\")\n",
        "plt.ylabel(\"Coefficient magnitude\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVAiTvloIGI6",
        "colab_type": "text"
      },
      "source": [
        "## ElasticNet regression\n",
        "\n",
        "> linear regression + L1 regularization + L2 regularization\n",
        "\n",
        "\n",
        "> $Loss_{elastic\\_net}=\\frac{1}{2N} \\sum_i{(\\hat{y}-y)^2} +a |W| +\\frac{1}{2}b|W|^2$\n",
        "\n",
        "> $Loss_{elastic\\_net}=\\frac{1}{2N} \\sum_i{(\\hat{y}-y)^2} +\\alpha\\cdot \\lambda |W| +\\frac{1}{2} \\alpha\\cdot(1-\\lambda)|W|^2$\n",
        "\n",
        " - $\\alpha$: weight of regularization (L1 + L2)\n",
        " - $\\lambda$: ratio of L1 regularization ($0 \\leq\\lambda\\leq 1$)\n",
        "\n",
        " - $\\alpha = a + b$, $\\lambda = \\frac{a}{a+b}$\n",
        "\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7LJsZi3iLE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import ElasticNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE0dNRNpiiFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# by default, alpha = 1, l1_ratio = 0.5\n",
        "elastic_net = ElasticNet().fit(X_train, y_train)\n",
        "print(\"Training score: {:.2f}\".format(elastic_net.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(elastic_net.score(X_test, y_test)))\n",
        "print(\"Number of features used:\", np.sum(elastic_net.coef_ != 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__lLPqsxjtfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alpha = 0.01\n",
        "elastic_net001 = ElasticNet(alpha=0.01, l1_ratio = 0.5).fit(X_train, y_train)\n",
        "print(\"Training set score: {:.2f}\".format(elastic_net001.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.2f}\".format(elastic_net001.score(X_test, y_test)))\n",
        "print(\"Number of features used:\", np.sum(elastic_net001.coef_ != 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L62piK-kVDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alpha = 0.001\n",
        "elastic_net0001 = ElasticNet(alpha=0.001, l1_ratio = 0.5).fit(X_train, y_train)\n",
        "print(\"Training score: {:.2f}\".format(elastic_net0001.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(elastic_net0001.score(X_test, y_test)))\n",
        "print(\"Number of features used:\", np.sum(elastic_net0001.coef_ != 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHZzoLTTkNNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alpha = 0.0001\n",
        "elastic_net00001 = ElasticNet(alpha=0.0001, l1_ratio = 0.5).fit(X_train, y_train)\n",
        "print(\"Training score: {:.2f}\".format(elastic_net00001.score(X_train, y_train)))\n",
        "print(\"Test score: {:.2f}\".format(elastic_net00001.score(X_test, y_test)))\n",
        "print(\"Number of features used:\", np.sum(elastic_net00001.coef_ != 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qhfeqH1ko99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(elastic_net.coef_, 'v', label=\"Lasso alpha=1\")\n",
        "plt.plot(elastic_net001.coef_, '^', label=\"ElasticNet alpha=0.01\")\n",
        "plt.plot(elastic_net0001.coef_, '^', label=\"ElasticNet alpha=0.001\")\n",
        "plt.plot(elastic_net00001.coef_, 's', label=\"Lasso alpha=0.0001\")\n",
        "\n",
        "#plt.plot(ridge01.coef_, 'o', label=\"Ridge alpha=0.1\")\n",
        "plt.legend(ncol=2, loc=(0, 1.05))\n",
        "plt.ylim(-25, 25)\n",
        "plt.xlabel(\"Coefficient index\")\n",
        "plt.ylabel(\"Coefficient magnitude\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKf1W0pMIHB4",
        "colab_type": "text"
      },
      "source": [
        "# Linear classification\n",
        "\n",
        "* Binary classification\n",
        "> - class +1 if $f(x) = \\sum_i{w_ix_i}+b = w_1 x_1 + w_2 x_2+...+b > 0$\n",
        "> - class -1 if $f(x) = \\sum_i{w_ix_i}+b = w_1 x_1 + w_2 x_2+...+b < 0$\n",
        "\n",
        "> Note! Class boundary is hyperplane\n",
        "\n",
        "* Multi-class classification: $ŷ = argmax_j {f_j(x)=[\\sum_i{w_{ji} x_i} + b_j]} = argmax_j {[w_{j1} x_1 + w_{j2} x_2+...+b_j]}$\n",
        "\n",
        "* Popular fitting algorithms\n",
        "> * Logistic regression (linear_model.LogisticRegression)\n",
        "> * (linear) Support Vector Machine (SVM)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d69750jZQJvZ",
        "colab_type": "text"
      },
      "source": [
        "## Logistic regression\n",
        "* binary classification ($y$ = 0 or 1)\n",
        "* $\\hat{y} = sigmoid(\\sum_i{w_ix_i+b})$\n",
        "* $ Loss_{logistic} = \\frac{1}{2N}(y - \\hat{y})^2 + \\alpha |W|_L$\n",
        "\n",
        "\n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRH0c5JWQPaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf1RXLuRHp_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "X, y = mglearn.datasets.make_forge()\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
        "for model, ax in zip([LogisticRegression(),LinearSVC()], axes):\n",
        "  clf = model.fit(X, y)\n",
        "  mglearn.plots.plot_2d_separator(clf, X, fill=False, eps=0.5, ax=ax, alpha=.7)\n",
        "  mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
        "  ax.set_title(\"{}\".format(clf.__class__.__name__))\n",
        "  ax.set_xlabel(\"Feature 0\")\n",
        "  ax.set_ylabel(\"Feature 1\")\n",
        "axes[0].legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm42jQgXNrzu",
        "colab_type": "text"
      },
      "source": [
        "## hyper parameter C to control regularization \n",
        "\n",
        "**small C** means **stronger regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGWcMZCTNeis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
        "\n",
        "# C = 1\n",
        "logreg = LogisticRegression().fit(X_train, y_train)\n",
        "print(\"Training score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
        "print(\"Test score: {:.3f}\".format(logreg.score(X_test, y_test))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZJ0DUbfN246",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# C = 100\n",
        "logreg100 = LogisticRegression(C=100).fit(X_train, y_train)\n",
        "print(\"Training score: {:.3f}\".format(logreg100.score(X_train, y_train)))\n",
        "print(\"Test score: {:.3f}\".format(logreg100.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdFGK--qN516",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# C = 0.01\n",
        "logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train)\n",
        "print(\"Training score: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
        "print(\"Test score: {:.3f}\".format(logreg001.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWX7yFmVN8tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(logreg.coef_.T, 'o', label=\"C=1\")\n",
        "plt.plot(logreg100.coef_.T, '^', label=\"C=100\")\n",
        "plt.plot(logreg001.coef_.T, 'v', label=\"C=0.001\")\n",
        "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
        "plt.hlines(0, 0, cancer.data.shape[1])\n",
        "plt.ylim(-5, 5)\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Coefficient magnitude\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usuW4OMg8YgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}